{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from transformers import pipeline\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"k4C4H8PUXa0FGpBrdbZpQg\",\n",
    "    client_secret=\"1Hv_M0wWh4LLYfpibEA5LGEm5lwH6Q\",\n",
    "    user_agent=\"search_treasurer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Content                Author  \\\n",
      "0  https://preview.redd.it/wqq4lz6mddcd1.png?widt...           dumbmoney99   \n",
      "1  RedWarFour, would u mind stfu. You have a prob...         victorconan90   \n",
      "2                                        Helllll yea           Happymeal85   \n",
      "3                                          Good news  Master_Flounder_9826   \n",
      "4  The Senior Director role is interesting so it ...       Tall_Walrus6481   \n",
      "\n",
      "  Subreddit  Score  NumComments             Created  \\\n",
      "0      FFIE    175           42 2024-07-13 16:24:21   \n",
      "1      FFIE     13            0 2024-07-13 20:07:17   \n",
      "2      FFIE      9            0 2024-07-13 16:56:11   \n",
      "3      FFIE      9            0 2024-07-13 18:10:49   \n",
      "4      FFIE      5            0 2024-07-13 19:23:47   \n",
      "\n",
      "                                                 URL       Type  \n",
      "0  https://www.reddit.com/r/FFIE/comments/1e2nvhj...  main post  \n",
      "1  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  \n",
      "2  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  \n",
      "3  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  \n",
      "4  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "search_term = \"ffie\"  # Replace with your desired search term\n",
    "subreddit = reddit.subreddit(\"FFIE\")\n",
    "\n",
    "data = []\n",
    "three_days_ago = datetime.utcnow() - timedelta(days=3)\n",
    "post_count = 0\n",
    "\n",
    "for submission in subreddit.search(search_term, limit=None):\n",
    "    if submission.created_utc >= three_days_ago.timestamp():\n",
    "        author = submission.author.name if submission.author else \"[deleted]\"\n",
    "        \n",
    "        # Add main post to data\n",
    "        data.append({\n",
    "            \"Content\": submission.selftext,\n",
    "            \"Author\": author,\n",
    "            \"Subreddit\": submission.subreddit.display_name,\n",
    "            \"Score\": submission.score,\n",
    "            \"NumComments\": submission.num_comments,\n",
    "            \"Created\": datetime.fromtimestamp(submission.created_utc),\n",
    "            \"URL\": submission.url,\n",
    "            \"Type\": \"main post\"\n",
    "        })\n",
    "\n",
    "        submission.comments.replace_more(limit=None)  # Load all comments\n",
    "        for comment in submission.comments.list():\n",
    "            comment_author = comment.author.name if comment.author else \"[deleted]\"\n",
    "\n",
    "            # Add comment to data\n",
    "            data.append({\n",
    "                \"Content\": comment.body,\n",
    "                \"Author\": comment_author,\n",
    "                \"Subreddit\": submission.subreddit.display_name,\n",
    "                \"Score\": comment.score,\n",
    "                \"NumComments\": 0, # Comments don't have nested comments\n",
    "                \"Created\": datetime.fromtimestamp(comment.created_utc),\n",
    "                \"URL\": comment.permalink,\n",
    "                \"Type\": \"comment\"\n",
    "            })\n",
    "\n",
    "        post_count += 1\n",
    "        if post_count % 100 == 0:\n",
    "            print(f\"Processed {post_count} posts...\")\n",
    "\n",
    "        if post_count >= 10000:  \n",
    "            break\n",
    "\n",
    "    time.sleep(2)  # Sleep for 2 seconds between requests (adjust as needed)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Author  Link Karma  Comment Karma  Is Employee  Is Mod  \\\n",
      "0           dumbmoney99       10024           5458        False    True   \n",
      "1         victorconan90          73            112        False   False   \n",
      "2           Happymeal85         551           1338        False   False   \n",
      "3  Master_Flounder_9826           1            742        False   False   \n",
      "4       Tall_Walrus6481         168           1925        False   False   \n",
      "\n",
      "      Account Created  \n",
      "0 2020-09-13 17:22:24  \n",
      "1 2016-09-19 10:34:06  \n",
      "2 2021-02-08 17:57:42  \n",
      "3 2022-03-30 17:39:13  \n",
      "4 2024-05-17 09:46:29  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get unique authors from the DataFrame\n",
    "unique_authors = df['Author'].unique()\n",
    "\n",
    "author_info = []\n",
    "for author_name in unique_authors:\n",
    "    if author_name != \"[deleted]\":\n",
    "        try:\n",
    "            redditor = reddit.redditor(author_name)\n",
    "            author_info.append({\n",
    "                \"Author\": redditor.name,\n",
    "                \"Link Karma\": redditor.link_karma,\n",
    "                \"Comment Karma\": redditor.comment_karma,\n",
    "                \"Is Employee\": redditor.is_employee,\n",
    "                \"Is Mod\": redditor.is_mod,\n",
    "                \"Account Created\": datetime.fromtimestamp(redditor.created_utc)\n",
    "            })\n",
    "        except praw.exceptions.RedditAPIException:\n",
    "            # Handle cases where the redditor might not exist or be inaccessible\n",
    "            print(f\"Could not fetch information for user: {author_name}\")\n",
    "            author_info.append({\n",
    "                \"Author\": author_name,\n",
    "                \"Link Karma\": None,\n",
    "                \"Comment Karma\": None,\n",
    "                \"Is Employee\": None,\n",
    "                \"Is Mod\": None,\n",
    "                \"Account Created\": None\n",
    "            })\n",
    "    else:\n",
    "        author_info.append({\n",
    "            \"Author\": author_name,\n",
    "            \"Link Karma\": None,\n",
    "            \"Comment Karma\": None,\n",
    "            \"Is Employee\": None,\n",
    "            \"Is Mod\": None,\n",
    "            \"Account Created\": None\n",
    "        })\n",
    "    time.sleep(1)  # Sleep for 1 second between requests\n",
    "\n",
    "# Create a new DataFrame with author information\n",
    "author_df = pd.DataFrame(author_info)\n",
    "print(author_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Author</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Score</th>\n",
       "      <th>NumComments</th>\n",
       "      <th>Created</th>\n",
       "      <th>URL</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://preview.redd.it/wqq4lz6mddcd1.png?widt...</td>\n",
       "      <td>dumbmoney99</td>\n",
       "      <td>FFIE</td>\n",
       "      <td>175</td>\n",
       "      <td>42</td>\n",
       "      <td>2024-07-13 16:24:21</td>\n",
       "      <td>https://www.reddit.com/r/FFIE/comments/1e2nvhj...</td>\n",
       "      <td>main post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RedWarFour, would u mind stfu. You have a prob...</td>\n",
       "      <td>victorconan90</td>\n",
       "      <td>FFIE</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-13 20:07:17</td>\n",
       "      <td>/r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Helllll yea</td>\n",
       "      <td>Happymeal85</td>\n",
       "      <td>FFIE</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-13 16:56:11</td>\n",
       "      <td>/r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good news</td>\n",
       "      <td>Master_Flounder_9826</td>\n",
       "      <td>FFIE</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-13 18:10:49</td>\n",
       "      <td>/r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Senior Director role is interesting so it ...</td>\n",
       "      <td>Tall_Walrus6481</td>\n",
       "      <td>FFIE</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-13 19:23:47</td>\n",
       "      <td>/r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content                Author  \\\n",
       "0  https://preview.redd.it/wqq4lz6mddcd1.png?widt...           dumbmoney99   \n",
       "1  RedWarFour, would u mind stfu. You have a prob...         victorconan90   \n",
       "2                                        Helllll yea           Happymeal85   \n",
       "3                                          Good news  Master_Flounder_9826   \n",
       "4  The Senior Director role is interesting so it ...       Tall_Walrus6481   \n",
       "\n",
       "  Subreddit  Score  NumComments             Created  \\\n",
       "0      FFIE    175           42 2024-07-13 16:24:21   \n",
       "1      FFIE     13            0 2024-07-13 20:07:17   \n",
       "2      FFIE      9            0 2024-07-13 16:56:11   \n",
       "3      FFIE      9            0 2024-07-13 18:10:49   \n",
       "4      FFIE      5            0 2024-07-13 19:23:47   \n",
       "\n",
       "                                                 URL       Type  \n",
       "0  https://www.reddit.com/r/FFIE/comments/1e2nvhj...  main post  \n",
       "1  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  \n",
       "2  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  \n",
       "3  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  \n",
       "4  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2897520513084b5982984dfe184bc38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w:\\Personal Projects\\Nvidia_Gen_AI_notebooks\\llmvenv\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\golla\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945d52e323374f89b1b5b6495d0e34bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c9a0e05f704b1fbb8a2c8579e82f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af455ce4dda342c19b59a3b32c6d6106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Content                Author  \\\n",
      "0  https://preview.redd.it/wqq4lz6mddcd1.png?widt...           dumbmoney99   \n",
      "1  RedWarFour, would u mind stfu. You have a prob...         victorconan90   \n",
      "2                                        Helllll yea           Happymeal85   \n",
      "3                                          Good news  Master_Flounder_9826   \n",
      "4  The Senior Director role is interesting so it ...       Tall_Walrus6481   \n",
      "\n",
      "  Subreddit  Score  NumComments             Created  \\\n",
      "0      FFIE    175           42 2024-07-13 16:24:21   \n",
      "1      FFIE     13            0 2024-07-13 20:07:17   \n",
      "2      FFIE      9            0 2024-07-13 16:56:11   \n",
      "3      FFIE      9            0 2024-07-13 18:10:49   \n",
      "4      FFIE      5            0 2024-07-13 19:23:47   \n",
      "\n",
      "                                                 URL       Type sentiment  \\\n",
      "0  https://www.reddit.com/r/FFIE/comments/1e2nvhj...  main post  NEGATIVE   \n",
      "1  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  POSITIVE   \n",
      "2  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  NEGATIVE   \n",
      "3  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  POSITIVE   \n",
      "4  /r/FFIE/comments/1e2nvhj/ffie_is_hiring_more_j...    comment  POSITIVE   \n",
      "\n",
      "   sentiment_confidence_score  \n",
      "0                    0.999529  \n",
      "1                    0.937881  \n",
      "2                    0.995271  \n",
      "3                    0.999859  \n",
      "4                    0.997973  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\") \n",
    "\n",
    "# Function to get sentiment and confidence from text with truncation\n",
    "def get_sentiment(text, max_length=512): \n",
    "    result = sentiment_pipeline(text[:max_length])[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "# Apply sentiment analysis with truncation to the content column\n",
    "df[['sentiment', 'sentiment_confidence_score']] = df['Content'].apply(lambda x: pd.Series(get_sentiment(x)))\n",
    "\n",
    "print(df.head())  # Display the updated DataFrame with sentiment and confidence columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "NEGATIVE    95\n",
       "POSITIVE    53\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment</th>\n",
       "      <th>NEGATIVE</th>\n",
       "      <th>POSITIVE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFIE</th>\n",
       "      <td>95</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment  NEGATIVE  POSITIVE\n",
       "Subreddit                    \n",
       "FFIE             95        53"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv1 = pd.pivot_table(df, index='Subreddit', columns='sentiment', values='Content', aggfunc='count', fill_value=0)\n",
    "pv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have df (post/comment data) and author_df (author information) from previous code\n",
    "\n",
    "# 1. Calculate Unique User Attention per Main Post\n",
    "main_post_df = df[df['Type'] == 'main post'].copy()\n",
    "unique_user_counts = main_post_df.groupby('Title')['Author'].nunique()\n",
    "unique_user_counts.name = 'UniqueUserAttention'\n",
    "\n",
    "# 2. Merge with Content DataFrame (Main Posts Only)\n",
    "merged_df = pd.merge(main_post_df, unique_user_counts, on='Title', how='left')\n",
    "\n",
    "# 3. Merge with Author DataFrame\n",
    "mega_df = pd.merge(merged_df, author_df, on='Author', how='left')\n",
    "\n",
    "print(mega_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
